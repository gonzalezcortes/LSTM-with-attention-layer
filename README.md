# LSTM with Explainability using an attention layer

In this notebook introduces a prediction using a Long Short-Term Memory (LSTM) with explainability. The data set used is "Power consumption of Tetouan city Data Set" from UCI Machine Learning Repository.

Also a prediction using XGBoost with different explanatory framework named SHAP was used to compare the LSTM with explainability.

Representation of the attention values:

<p align="center" width="100%">
    <img width="100%" src="attention_values.jpg">
</p>

Keras architecture:


<p align="center" width="100%">
    <img width="50%" src="index.png">
</p>
